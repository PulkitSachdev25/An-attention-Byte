{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PulkitSachdev25/An-attention-Byte/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# INSTALLS\n",
        "# =========================\n",
        "!apt-get update -qq\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install gradio moviepy ffmpeg-python pydub faster-whisper vaderSentiment opencv-python-headless\n",
        "\n",
        "# =========================\n",
        "# GRADIO APP\n",
        "# =========================\n",
        "import gradio as gr\n",
        "import os, cv2, ffmpeg, numpy as np\n",
        "from moviepy.editor import VideoFileClip, VideoClip, CompositeVideoClip, ColorClip\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "from faster_whisper import WhisperModel\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def process_video(video_file):\n",
        "    try:\n",
        "        os.makedirs(\"temp_output\", exist_ok=True)\n",
        "        import shutil\n",
        "        shutil.copy(video_file, \"input.mp4\")\n",
        "        return \"Saved video. Now processing‚Ä¶\", []\n",
        "    except Exception as e:\n",
        "        return f\"Error saving video: {e}\", []\n",
        "# ---------------- GRADIO INTERFACE ----------------\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=gr.Video(label=\"Upload MP4\"),\n",
        "    outputs=[gr.Textbox(label=\"Status\"), gr.File(label=\"Download Reels\")],\n",
        "    title=\"üé¨ Reel-Worthy Clip Generator\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "OGdpSUNywDN2",
        "outputId": "b8f614c6-5320-4ecb-8dcc-b95b023647cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6d35c2542f89a44423.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6d35c2542f89a44423.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1Lh1pXJcJVTK",
        "outputId": "15d7bfd9-a982-4561-8892-822244be0077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "!pip install textblob\n",
        "!python -m textblob.download_corpora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YnmBcNWnxzQX",
        "outputId": "7ba082af-48d6-448e-958f-3eef62c8894b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VTYwOoXpq7F",
        "outputId": "cb6a27cf-fce6-415f-c112-905f54541be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 2090.75 seconds\n",
            "FPS: 30.0\n",
            "Resolution: 1920x1080\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "video_path = \"test.mp4\"\n",
        "clip = VideoFileClip(video_path)\n",
        "duration = clip.duration        # seconds (float)\n",
        "fps = clip.fps\n",
        "width, height = clip.size\n",
        "\n",
        "print(f\"Duration: {duration:.2f} seconds\")\n",
        "print(f\"FPS: {fps}\")\n",
        "print(f\"Resolution: {width}x{height}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sTKvkjbNeIY",
        "outputId": "4c49c663-74f1-4f4f-8858-825a5e91c5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio extracted to: myaudio.wav\n"
          ]
        }
      ],
      "source": [
        "import ffmpeg\n",
        "audio_path = \"myaudio.wav\"\n",
        "ffmpeg.input(video_path).output(audio_path).run(overwrite_output=True)\n",
        "print(\"audio extracted to:\",audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJU3b9VLOwTd",
        "outputId": "24ae4a92-b1bd-499c-e9cf-a366dd47bea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: -15 dB | Candidate clips: 10\n",
            "Final candidate clips (seconds): [[58.5, 118.5], [624.5, 684.5], [668.5, 728.5], [788.5, 848.5], [819.5, 879.5], [885.5, 945.5], [1185.5, 1245.5], [1224.5, 1284.5], [1717.5, 1777.5], [1866.5, 1926.5]]\n"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "\n",
        "audio = AudioSegment.from_wav(\"myaudio.wav\")\n",
        "\n",
        "# Desired number of candidate clips\n",
        "CLIP_MIN_PEAKS = 10\n",
        "CLIP_MAX_PEAKS = 15\n",
        "CHUNK_MS = 1000  # 1 second chunks\n",
        "MERGE_GAP = 5000  # merge peaks within 5 seconds\n",
        "TARGET_CLIP_DURATION = 60  # seconds\n",
        "\n",
        "THRESHOLD_START = -15\n",
        "THRESHOLD_MIN = -40\n",
        "THRESHOLD_STEP = 1\n",
        "\n",
        "threshold_db = THRESHOLD_START\n",
        "success = False\n",
        "\n",
        "while threshold_db >= THRESHOLD_MIN:\n",
        "    chunks = make_chunks(audio, CHUNK_MS)\n",
        "    peaks = []\n",
        "\n",
        "    # Step 1: find peaks above threshold\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if chunk.dBFS >= threshold_db:\n",
        "            peaks.append(i * CHUNK_MS)\n",
        "\n",
        "    # Step 2: merge nearby peaks\n",
        "    merged = []\n",
        "    if peaks:\n",
        "        start = peaks[0]\n",
        "        end = peaks[0]\n",
        "        for t in peaks[1:]:\n",
        "            if t - end <= MERGE_GAP:\n",
        "                end = t\n",
        "            else:\n",
        "                merged.append([start / 1000, (end + CHUNK_MS) / 1000])\n",
        "                start = end = t\n",
        "        merged.append([start / 1000, (end + CHUNK_MS) / 1000])\n",
        "\n",
        "        # Step 3: expand/clip to ~60 seconds\n",
        "        final_clips = []\n",
        "        for s, e in merged:\n",
        "            duration = e - s\n",
        "            if duration < TARGET_CLIP_DURATION:\n",
        "                # try to expand equally on both sides without exceeding audio limits\n",
        "                extra = TARGET_CLIP_DURATION - duration\n",
        "                new_start = max(0, s - extra / 2)\n",
        "                new_end = min(audio.duration_seconds, e + extra / 2)\n",
        "                final_clips.append([new_start, new_end])\n",
        "            elif duration > TARGET_CLIP_DURATION:\n",
        "                # if too long, just take the first 60 seconds\n",
        "                final_clips.append([s, s + TARGET_CLIP_DURATION])\n",
        "            else:\n",
        "                final_clips.append([s, e])\n",
        "        merged = final_clips\n",
        "\n",
        "    else:\n",
        "        merged = []\n",
        "\n",
        "    print(f\"Threshold: {threshold_db} dB | Candidate clips: {len(merged)}\")\n",
        "\n",
        "    if CLIP_MIN_PEAKS <= len(merged) <= CLIP_MAX_PEAKS:\n",
        "        success = True\n",
        "        break\n",
        "    elif len(merged) < CLIP_MIN_PEAKS:\n",
        "        threshold_db -= THRESHOLD_STEP\n",
        "    else:\n",
        "        threshold_db += THRESHOLD_STEP\n",
        "\n",
        "if not success:\n",
        "    print(\"Couldn't find proper peaks for desired clip count!\")\n",
        "else:\n",
        "    print(\"Final candidate clips (seconds):\", merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S18Xg86_ftYz",
        "outputId": "5cf22a7e-85a4-4979-c8d7-af9b198b06bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.2.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.2)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Downloading faster_whisper-1.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-16.1.0 coloredlogs-15.0.1 ctranslate2-4.6.3 faster-whisper-1.2.1 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "audio = AudioSegment.from_file(\"myaudio.wav\")\n",
        "model = WhisperModel(\"medium\", device=\"cuda\", compute_type=\"int8\")\n",
        "\n",
        "all_clip_transcripts = []  # store transcripts per clip\n",
        "\n",
        "for i, (start, end) in enumerate(merged, 1):\n",
        "    start_ms, end_ms = int(start * 1000), int(end * 1000)\n",
        "    clip_audio = audio[start_ms:end_ms]\n",
        "\n",
        "    temp_path = f\"audio_clip_{i}.wav\"\n",
        "    clip_audio.export(temp_path, format=\"wav\")\n",
        "\n",
        "    segments, info = model.transcribe(temp_path, beam_size=5, language=\"en\")\n",
        "\n",
        "    clip_transcript = []\n",
        "    for seg in segments:\n",
        "        clip_transcript.append({\n",
        "            \"start\": seg.start,  # relative to this audio clip\n",
        "            \"end\": seg.end,\n",
        "            \"text\": seg.text.strip()\n",
        "        })\n",
        "\n",
        "    # store transcript under clip index\n",
        "    all_clip_transcripts.append({\n",
        "        \"clip_idx\": i,\n",
        "        \"transcript\": clip_transcript\n",
        "    })\n",
        "\n",
        "# Example: printing per clip\n",
        "for clip in all_clip_transcripts:\n",
        "    print(f\"Clip {clip['clip_idx']} transcript:\")\n",
        "    for seg in clip['transcript']:\n",
        "        print(f\"{seg['start']:.2f}-{seg['end']:.2f}: {seg['text']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XnlWQ6n1hqIz",
        "outputId": "37e2f7f8-87c2-470c-921b-47b6ed90c7b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clip 1 transcript:\n",
            "0.00-2.64: specific technologies like deep tech or something else.\n",
            "2.64-5.04: But if your fundamentals are not clear,\n",
            "5.04-9.72: then no point in hopping onto other things.\n",
            "9.72-11.48: So Lakshya, we have a few questions.\n",
            "11.48-14.28: Would you like to take up one or two, and maybe we can then\n",
            "14.28-15.00: proceed further?\n",
            "15.00-16.84: Yes, we can take one or two.\n",
            "16.84-19.20: So Vanshika is asking, ma'am,\n",
            "19.20-22.88: please tell the correct way for doing DSA.\n",
            "22.88-24.84: Correct way for doing DSA?\n",
            "24.84-29.84: So correct way for doing DSA is not\n",
            "29.88-31.44: one way works for everyone.\n",
            "31.44-36.44: But one thing I can suggest is that have a basic knowledge\n",
            "36.52-38.52: about all the data structures.\n",
            "38.52-42.64: It should be like breadth first and depth later.\n",
            "42.64-45.56: And it should not be like you don't have depth at all.\n",
            "45.56-48.16: But it should not be like, it should be a balance\n",
            "48.16-50.76: between depth and breadth of a data structure.\n",
            "50.76-54.84: So like take basics, basic start from strings,\n",
            "54.84-57.80: then arrays, then lists, and so on.\n",
            "57.80-60.24: But also go in a little depth.\n",
            "---\n",
            "Clip 2 transcript:\n",
            "0.00-3.44: Engaging the interviewer and make it a point.\n",
            "3.44-12.84: Because the interviewer is assessing how much ease we will have with this person while working.\n",
            "12.84-18.64: If he or she is on board to our team and working alongside me in this project.\n",
            "18.64-22.80: And next is what are the problem solving capabilities of this person.\n",
            "22.80-24.48: How this person thinks.\n",
            "24.48-28.48: These are the three things that a person wants to understand from this technical round.\n",
            "28.48-35.32: So that is what you need to make sure that you are taking that in mind while solving these problems.\n",
            "35.32-39.92: And how do you make sure that you are taking these things in your...\n",
            "39.92-43.92: You know, because it is not in our habit.\n",
            "43.92-46.92: When we are practicing lead code, we read normal questions.\n",
            "46.92-50.32: We wear paper and think of the solution and we code it.\n",
            "50.32-51.92: Or maybe you directly code it.\n",
            "51.92-55.32: Because you have that in mind that how we are going to solve this.\n",
            "55.32-60.16: We don't talk by typing or maybe typing the solution.\n",
            "---\n",
            "Clip 3 transcript:\n",
            "0.00-6.00: When we practice lead code, we read a normal question, we think of a solution on paper and we code it.\n",
            "6.00-11.00: Or maybe you directly code it because you have that in mind that how are we going to solve it.\n",
            "11.00-16.00: We don't talk by typing or maybe typing the solution.\n",
            "16.00-24.00: So when you practice, once your concepts are clear, then take it in lead code or take it in hacker angle.\n",
            "24.00-29.00: Always practice that you practice it while speaking.\n",
            "29.00-35.00: You are explaining it to someone, maybe record it so that you also know how you are explaining it.\n",
            "35.00-39.00: Then evaluate it yourself.\n",
            "39.00-44.00: If I was an interviewer, do you understand what I am doing?\n",
            "44.00-46.00: Am I able to explain everything?\n",
            "46.00-49.00: That will help you also understand.\n",
            "49.00-56.00: And after that maybe you can team up with your friends, maybe your mentors that have a mock interview.\n",
            "56.00-58.00: Get a feedback and improvise on that.\n",
            "58.00-60.00: Practice is something that makes a difference.\n",
            "---\n",
            "Clip 4 transcript:\n",
            "0.00-12.00: Awesome. So guys, this is very, very important insights on how to tackle a technical problem.\n",
            "12.00-19.00: Because knowing technical knowledge, having technical insight, knowing data structures is one thing.\n",
            "19.00-23.00: But how do you structure that in an interview and explain it?\n",
            "24.00-26.00: That is entirely different ballgame.\n",
            "26.00-32.00: Most people, after losing 3-4-5 interviews, after failing from those interviews, they realize.\n",
            "32.00-36.00: Or even after experiencing 3-4 interviews, they understand these things.\n",
            "36.00-43.00: So today you have learned from Lakshya's experience herself, how to tackle a technical problem.\n",
            "43.00-49.00: I hope this gives you good insights, guys. So we'll move ahead.\n",
            "49.00-53.00: Raghav, before we move, I think I want to add one anecdote here.\n",
            "53.00-58.00: So talking about one of my interview rounds. It was, I think, fresh out of college.\n",
            "58.00-60.00: I joined my company. I was like, okay, I will...\n",
            "---\n",
            "Clip 5 transcript:\n",
            "0.00-12.00: So today you have learned from Lakshya's experience herself that how to tackle the technical problem.\n",
            "12.00-18.00: I hope this gives you good insights guys. So we'll move ahead.\n",
            "18.00-22.00: Raghav, before we move, I think I want to add one anecdote here.\n",
            "22.00-28.00: So talking about one of my interview rounds, like it was I think fresh out of college, I joined my company.\n",
            "28.00-34.00: I was like okay, I just want to once, I want to have my hand that I can crack Google.\n",
            "34.00-37.00: And what I did was without any practice, I just landed.\n",
            "37.00-43.00: I got a call from HR that I am scheduling your interview and my interview is scheduled.\n",
            "43.00-47.00: And it was a very basic question and I had solved it.\n",
            "47.00-53.00: But what happened was I had a cold feet. I was not able to solve that easiest question of strings.\n",
            "53.00-59.00: So that can also happen. But what that taught me was that I need to practice.\n",
            "---\n",
            "Clip 6 transcript:\n",
            "0.00-3.80: interviewer ko bhi nahi show karna hai because interviewer can make it complex that is what\n",
            "3.80-4.80: happened with me.\n",
            "4.80-9.12: So these are some points that I also added by making the points clear to you.\n",
            "9.12-10.76: So aisa ho sakta hai.\n",
            "10.76-16.56: So takhi aapko cold feet nahi ho, takhi aap nervous nahi ho, always make sure that\n",
            "16.56-21.62: you have a mock interview before at least interviewing for your dream company but\n",
            "21.62-25.68: I would say, chahe wo koi bhi company ho, even if it is not your dream company\n",
            "25.68-30.56: always have a mock interview with your friends, with your mentors, whomever you can give a\n",
            "30.56-38.48: mock interview with so that you just don't feel nervous at all while giving that interview.\n",
            "38.48-39.48: Make that point.\n",
            "39.48-40.48: Very interesting.\n",
            "40.48-46.16: So Lakshya, we will take one or two more questions in the chat we already have.\n",
            "46.16-50.20: So Tanistha is asking, please suggest some project ideas.\n",
            "50.20-56.72: So anything you want to comment to Tanistha on general on how to find the project ideas.\n",
            "---\n",
            "Clip 7 transcript:\n",
            "0.00-7.24: that company okay and always thank an interviewer after ending your problem\n",
            "7.24-11.12: solving and at the end of the interview and do not ask any of the\n",
            "11.12-17.22: dumb questions so sharing one of the questions from one of my team like we\n",
            "17.22-21.84: were interviewing recently at Oracle and one of the interviewee asked us\n",
            "21.84-26.20: one of the questions like how does your work relate to invention of\n",
            "26.20-32.72: electricity like we were like spellbound what do we say here and don't ask such\n",
            "32.72-37.12: questions you are not testing an interviewer you are just you just want\n",
            "37.12-41.82: to understand the culture of the team culture of the company you want to\n",
            "41.82-46.70: understand how the company operates and how you can add to that company so\n",
            "46.70-51.48: have your questions around that don't test your interviewer and let them\n",
            "51.48-56.24: be spellbound and then we think like no yaar yeh aise question puch raha hai may be\n",
            "56.24-61.64: bhaad mein kya kareega don't don't be like that\n",
            "---\n",
            "Clip 8 transcript:\n",
            "0.00-5.32: team, culture of the company. You want to understand how the company operates and how\n",
            "5.32-10.64: you can add to that company. So have your questions around that. Don't test your interviewer\n",
            "10.64-17.08: and let them be spellbound and they will be thinking like, no, he is asking such a question,\n",
            "17.08-21.00: what will he do later? Don't be like that.\n",
            "21.00-27.96: I think Lakshya and I were discussing few days back about the same instance Lakshya\n",
            "27.96-33.52: was discussing with me, on how the interview went superb and they were on the verge of selecting\n",
            "33.52-39.76: a candidate because he technically got all the answers right, everything was going right\n",
            "39.76-47.80: but just his last question made him get rejected from Oracle. Can you believe it? Because\n",
            "47.80-52.76: he asked such a dumb question to the interviewer. The interviewer said that I don't want\n",
            "52.76-57.24: to work like this kind of a candidate who is asking this kind of a question, how does\n",
            "57.24-59.96: the invention of electricity relates to your work?\n",
            "---\n",
            "Clip 9 transcript:\n",
            "0.00-4.84: with patterns so once you are having a question and while in an interview you will be able\n",
            "4.84-8.60: to relate ki aap isko kaunse patterns se solve karne even if that question is something\n",
            "8.60-12.08: that you have never seen I hope that helps you.\n",
            "12.08-16.90: Awesome I hope this answers your question Kashish.\n",
            "16.90-22.96: So further questions we have is from Chetanya is asking how many minutes can we give our\n",
            "22.96-24.68: intro round.\n",
            "24.68-28.72: So how long should be the intro Lakshya Chetanya is asking 1 to 2 minutes not\n",
            "28.72-33.72: more than that because you have 45 minutes with you and the end goal of that interview\n",
            "33.72-38.52: is you are going to solve a DSA problem maybe one or two so that's very important.\n",
            "38.52-42.80: And it should not be even 15-20 seconds it should be bit longer but not that longer\n",
            "42.80-43.80: also.\n",
            "43.80-47.68: Yeah so 1 to 2 minutes is an ideal one I guess.\n",
            "47.68-48.68: Awesome.\n",
            "48.68-52.16: Arshia is asking any tips on how to handle follow up questions when you are unsure\n",
            "52.16-54.28: of the answer.\n",
            "54.28-60.00: Like is that unsure of an answer for a DSA problem.\n",
            "---\n",
            "Clip 10 transcript:\n",
            "0.00-6.00: How do we handle when the answer is not?\n",
            "6.00-7.96: I think that is a really good question.\n",
            "7.96-11.48: Sometimes it happens that we get a question that we don't know about.\n",
            "11.48-18.24: So obviously you should once give a try to that question, ask clarifying questions,\n",
            "18.24-25.36: try to ask as many questions as you can to make yourself clear, ask about constraints,\n",
            "25.36-34.64: ask about examples, maybe think about an example yourself about how many questions you have understood.\n",
            "34.64-40.64: It's not like you are just asking the interviewer, maybe the interviewer also has a perspective\n",
            "40.64-46.64: that you are trying to ask the solution around, make an example of yourself, explain it that\n",
            "46.64-50.64: you have understood so much, is it what that you are expecting and then you can follow up.\n",
            "50.64-54.96: So these are some strategies that maybe you can follow and maybe sometimes I also follow.\n",
            "54.96-58.96: If I don't know at all that what is that question.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Store clip sentiment and priority\n",
        "clip_sentiments = []\n",
        "\n",
        "for clip in all_clip_transcripts:\n",
        "    clip_idx = clip['clip_idx']\n",
        "\n",
        "    # Merge all text segments into one string per clip\n",
        "    full_text = \" \".join([seg['text'] for seg in clip['transcript']])\n",
        "\n",
        "    # Compute VADER sentiment\n",
        "    score = analyzer.polarity_scores(full_text)['compound']  # compound score ranges -1 to 1\n",
        "\n",
        "       # Get clip start and end times from segments\n",
        "    clip_start = clip['transcript'][0]['start']\n",
        "    clip_end = clip['transcript'][-1]['end']\n",
        "    duration = clip_end - clip_start\n",
        "    clip_sentiments.append({\n",
        "        \"clip_idx\": clip_idx,\n",
        "        \"score\": score,\n",
        "        \"text\": full_text\n",
        "    })\n",
        "\n",
        "# Sort clips by sentiment descending (best first)\n",
        "clip_sentiments.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "# Take top 5 clips (or fewer if less exist)\n",
        "top_clips = clip_sentiments[:5]\n",
        "\n",
        "# Assign priority (1 = best)\n",
        "for priority, clip in enumerate(top_clips, 1):\n",
        "    clip['priority'] = priority\n",
        "\n",
        "# Print final selection\n",
        "print(\"Top clips by sentiment priority:\")\n",
        "for clip in top_clips:\n",
        "    print(f\"Priority {clip['priority']}: Clip {clip['clip_idx']} | Score={clip['score']:.2f}\")\n",
        "    print(f\"Text (truncated): {clip['text'][:150]}...\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LRpx9rgYihIR",
        "outputId": "05f1fc86-5f46-4824-ed87-86b15e464f6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2026.1.4)\n",
            "Top clips by sentiment priority:\n",
            "Priority 1: Clip 9 | Score=0.93\n",
            "Text (truncated): with patterns so once you are having a question and while in an interview you will be able to relate ki aap isko kaunse patterns se solve karne even i...\n",
            "---\n",
            "Priority 2: Clip 1 | Score=0.93\n",
            "Text (truncated): specific technologies like deep tech or something else. But if your fundamentals are not clear, then no point in hopping onto other things. So Lakshya...\n",
            "---\n",
            "Priority 3: Clip 7 | Score=0.93\n",
            "Text (truncated): that company okay and always thank an interviewer after ending your problem solving and at the end of the interview and do not ask any of the dumb que...\n",
            "---\n",
            "Priority 4: Clip 2 | Score=0.91\n",
            "Text (truncated): Engaging the interviewer and make it a point. Because the interviewer is assessing how much ease we will have with this person while working. If he or...\n",
            "---\n",
            "Priority 5: Clip 5 | Score=0.89\n",
            "Text (truncated): So today you have learned from Lakshya's experience herself that how to tackle the technical problem. I hope this gives you good insights guys. So we'...\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip, VideoClip, CompositeVideoClip, ColorClip, TextClip\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Add start/end/duration to top clips\n",
        "# ----------------------------\n",
        "for clip in top_clips:\n",
        "    idx = clip[\"clip_idx\"] - 1  # zero-based index\n",
        "    clip[\"start\"] = merged[idx][0]\n",
        "    clip[\"end\"]   = merged[idx][1]\n",
        "    clip[\"duration\"] = clip[\"end\"] - clip[\"start\"]\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Video settings\n",
        "# ----------------------------\n",
        "TARGET_WIDTH = 1080\n",
        "TARGET_HEIGHT = 1920\n",
        "TARGET_ASPECT = TARGET_WIDTH / TARGET_HEIGHT\n",
        "\n",
        "FONT_SCALE = 1.2\n",
        "THICKNESS = 3\n",
        "PADDING = 30  # distance from bottom\n",
        "LINE_SPACING = 10\n",
        "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "TEXT_COLOR = (255, 255, 255)\n",
        "BG_COLOR = (0, 0, 0)\n",
        "MAX_WIDTH_RATIO = 0.9\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(\"final_clips\", exist_ok=True)\n",
        "os.makedirs(\"final_clips_vertical\", exist_ok=True)\n",
        "os.makedirs(\"final_clips_subtitled\", exist_ok=True)\n",
        "\n",
        "# Load full video\n",
        "full_video_path = \"test.mp4\"\n",
        "full_video = VideoFileClip(full_video_path)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Process each top clip\n",
        "# ----------------------------\n",
        "for priority, clip in enumerate(top_clips, 1):\n",
        "    start_time = clip[\"start\"]\n",
        "    end_time   = clip[\"end\"]\n",
        "\n",
        "    # 3a. Extract subclip\n",
        "    subclip = full_video.subclip(start_time, end_time)\n",
        "    temp_clip_path = f\"final_clips/clip_{priority}_idx{clip['clip_idx']}.mp4\"\n",
        "    subclip.write_videofile(temp_clip_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "    print(f\"Saved Clip {priority} | Duration: {clip['duration']:.2f}s\")\n",
        "\n",
        "    # 3b. Convert to vertical 9:16\n",
        "    w, h = subclip.size\n",
        "    aspect = w / h\n",
        "\n",
        "    if aspect > TARGET_ASPECT:\n",
        "        # Wider than 9:16\n",
        "        new_w = TARGET_WIDTH\n",
        "        new_h = int(TARGET_WIDTH / aspect)\n",
        "    else:\n",
        "        # Taller than 9:16\n",
        "        new_h = TARGET_HEIGHT\n",
        "        new_w = int(TARGET_HEIGHT * aspect)\n",
        "\n",
        "    video_resized = subclip.resize(newsize=(new_w, new_h))\n",
        "    background = ColorClip(size=(TARGET_WIDTH, TARGET_HEIGHT), color=(0,0,0)).set_duration(video_resized.duration)\n",
        "    vertical_clip = CompositeVideoClip([background.set_position(\"center\"), video_resized.set_position(\"center\")])\n",
        "    vertical_path = f\"final_clips_vertical/clip_{priority}_idx{clip['clip_idx']}_vertical.mp4\"\n",
        "    vertical_clip.write_videofile(vertical_path, fps=24, audio_codec=\"aac\")\n",
        "    print(f\"Saved vertical Clip {priority}\")\n",
        "\n",
        "    # 3c. Add subtitles\n",
        "    # Get transcript for this clip\n",
        "    clip_transcript = all_clip_transcripts[clip[\"clip_idx\"] - 1][\"transcript\"]\n",
        "    segments = []\n",
        "    for seg in clip_transcript:\n",
        "        # clip-relative timestamps\n",
        "        rel_start = max(0, seg['start'])\n",
        "        rel_end   = min(subclip.duration, seg['end'])\n",
        "        segments.append({\n",
        "            \"start\": rel_start,\n",
        "            \"end\": rel_end,\n",
        "            \"text\": seg['text']\n",
        "        })\n",
        "\n",
        "    # Function to draw subtitles on each frame\n",
        "    def make_frame(t):\n",
        "        frame = vertical_clip.get_frame(t)\n",
        "        frame = np.array(frame)\n",
        "        active_subs = [s for s in segments if s['start'] <= t <= s['end']]\n",
        "        if not active_subs:\n",
        "            return frame\n",
        "\n",
        "        for sub in active_subs:\n",
        "            text = sub['text']\n",
        "            max_width = int(vertical_clip.w * MAX_WIDTH_RATIO)\n",
        "            # Wrap text\n",
        "            words = text.split()\n",
        "            lines = []\n",
        "            current_line = \"\"\n",
        "            for word in words:\n",
        "                test_line = current_line + \" \" + word if current_line else word\n",
        "                (tw, th), _ = cv2.getTextSize(test_line, FONT, FONT_SCALE, THICKNESS)\n",
        "                if tw > max_width:\n",
        "                    lines.append(current_line)\n",
        "                    current_line = word\n",
        "                else:\n",
        "                    current_line = test_line\n",
        "            if current_line:\n",
        "                lines.append(current_line)\n",
        "\n",
        "            # Draw background rectangle\n",
        "            total_text_height = len(lines) * (int(FONT_SCALE*30) + LINE_SPACING)\n",
        "            y0 = vertical_clip.h - total_text_height - PADDING\n",
        "            y1 = y0 + total_text_height + 20\n",
        "            cv2.rectangle(frame, (0, y0-10), (vertical_clip.w, y1), BG_COLOR, -1)\n",
        "\n",
        "            # Draw each line\n",
        "            y = y0\n",
        "            for line in lines:\n",
        "                (tw, th), _ = cv2.getTextSize(line, FONT, FONT_SCALE, THICKNESS)\n",
        "                x = int((vertical_clip.w - tw)/2)\n",
        "                cv2.putText(frame, line, (x, y+th), FONT, FONT_SCALE, TEXT_COLOR, THICKNESS, cv2.LINE_AA)\n",
        "                y += th + LINE_SPACING\n",
        "        return frame\n",
        "\n",
        "    subtitled_clip = VideoClip(make_frame, duration=vertical_clip.duration)\n",
        "    subtitled_clip = subtitled_clip.set_audio(vertical_clip.audio)\n",
        "    final_sub_path = f\"final_clips_subtitled/clip_{priority}_idx{clip['clip_idx']}_subtitled.mp4\"\n",
        "    subtitled_clip.write_videofile(final_sub_path, fps=24, audio_codec=\"aac\")\n",
        "    print(f\"Saved subtitled Clip {priority}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mJHxXjUDoti3",
        "outputId": "d1fb3567-4236-40e3-f46f-ad6cc340b5f0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video final_clips/clip_1_idx9.mp4.\n",
            "MoviePy - Writing audio in clip_1_idx9TEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips/clip_1_idx9.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips/clip_1_idx9.mp4\n",
            "Saved Clip 1 | Duration: 60.00s\n",
            "Moviepy - Building video final_clips_vertical/clip_1_idx9_vertical.mp4.\n",
            "MoviePy - Writing audio in clip_1_idx9_verticalTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_vertical/clip_1_idx9_vertical.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_vertical/clip_1_idx9_vertical.mp4\n",
            "Saved vertical Clip 1\n",
            "Moviepy - Building video final_clips_subtitled/clip_1_idx9_subtitled.mp4.\n",
            "MoviePy - Writing audio in clip_1_idx9_subtitledTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_subtitled/clip_1_idx9_subtitled.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_subtitled/clip_1_idx9_subtitled.mp4\n",
            "Saved subtitled Clip 1\n",
            "Moviepy - Building video final_clips/clip_2_idx1.mp4.\n",
            "MoviePy - Writing audio in clip_2_idx1TEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips/clip_2_idx1.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips/clip_2_idx1.mp4\n",
            "Saved Clip 2 | Duration: 60.00s\n",
            "Moviepy - Building video final_clips_vertical/clip_2_idx1_vertical.mp4.\n",
            "MoviePy - Writing audio in clip_2_idx1_verticalTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_vertical/clip_2_idx1_vertical.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_vertical/clip_2_idx1_vertical.mp4\n",
            "Saved vertical Clip 2\n",
            "Moviepy - Building video final_clips_subtitled/clip_2_idx1_subtitled.mp4.\n",
            "MoviePy - Writing audio in clip_2_idx1_subtitledTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_subtitled/clip_2_idx1_subtitled.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_subtitled/clip_2_idx1_subtitled.mp4\n",
            "Saved subtitled Clip 2\n",
            "Moviepy - Building video final_clips/clip_3_idx7.mp4.\n",
            "MoviePy - Writing audio in clip_3_idx7TEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips/clip_3_idx7.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips/clip_3_idx7.mp4\n",
            "Saved Clip 3 | Duration: 60.00s\n",
            "Moviepy - Building video final_clips_vertical/clip_3_idx7_vertical.mp4.\n",
            "MoviePy - Writing audio in clip_3_idx7_verticalTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_vertical/clip_3_idx7_vertical.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_vertical/clip_3_idx7_vertical.mp4\n",
            "Saved vertical Clip 3\n",
            "Moviepy - Building video final_clips_subtitled/clip_3_idx7_subtitled.mp4.\n",
            "MoviePy - Writing audio in clip_3_idx7_subtitledTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_subtitled/clip_3_idx7_subtitled.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips_subtitled/clip_3_idx7_subtitled.mp4\n",
            "Saved subtitled Clip 3\n",
            "Moviepy - Building video final_clips/clip_4_idx2.mp4.\n",
            "MoviePy - Writing audio in clip_4_idx2TEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips/clip_4_idx2.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_clips/clip_4_idx2.mp4\n",
            "Saved Clip 4 | Duration: 60.00s\n",
            "Moviepy - Building video final_clips_vertical/clip_4_idx2_vertical.mp4.\n",
            "MoviePy - Writing audio in clip_4_idx2_verticalTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_clips_vertical/clip_4_idx2_vertical.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 780/1440 [01:08<00:51, 12.89it/s, now=None]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-345230557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mvertical_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompositeVideoClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mvertical_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"final_clips_vertical/clip_{priority}_idx{clip['clip_idx']}_vertical.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mvertical_clip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertical_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_codec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aac\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved vertical Clip {priority}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-172>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    133\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<decorator-gen-171>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    298\u001b[0m                                        logger=logger)\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         ffmpeg_write_video(self, filename, fps, codec,\n\u001b[0m\u001b[1;32m    301\u001b[0m                            \u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbitrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                            \u001b[0mpreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mnframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         for t,frame in clip.iter_frames(logger=logger, with_times=True,\n\u001b[0m\u001b[1;32m    221\u001b[0m                                         fps=fps, dtype=\"uint8\"):\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36miter_frames\u001b[0;34m(self, fps, with_times, logger, dtype)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproglog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bar_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-129>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/compositing/CompositeVideoClip.py\u001b[0m in \u001b[0;36mmake_frame\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaying_clips\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mblit_on\u001b[0;34m(self, picture, t)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# GET IMAGE AND MASK IF ANY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-129>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/fx/resize.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mfl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/moviepy/video/fx/resize.py\u001b[0m in \u001b[0;36mresizer\u001b[0;34m(pic, newsize)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# For dowsizing use area to prevent aliasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         return cv2.resize(+pic.astype('uint8'), (lx, ly),\n\u001b[0m\u001b[1;32m     17\u001b[0m                           interpolation=interpolation)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBVo6hWcFOQHMMoMzPjyo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}